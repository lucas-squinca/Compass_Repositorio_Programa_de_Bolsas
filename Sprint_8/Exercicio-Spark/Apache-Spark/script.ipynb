{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|             _c0|\n",
      "+----------------+\n",
      "|  Frances Bennet|\n",
      "|   Jamie Russell|\n",
      "|  Edward Kistler|\n",
      "|   Sheila Maurer|\n",
      "|Donald Golightly|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SQLContext\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Exercicio Intro\").getOrCreate()\n",
    "\n",
    "\n",
    "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\", header=False, inferSchema=True)\n",
    "\n",
    "\n",
    "df_nomes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Nomes: string (nullable = true)\n",
      "\n",
      "+-----------------+\n",
      "|            Nomes|\n",
      "+-----------------+\n",
      "|   Frances Bennet|\n",
      "|    Jamie Russell|\n",
      "|   Edward Kistler|\n",
      "|    Sheila Maurer|\n",
      "| Donald Golightly|\n",
      "|       David Gray|\n",
      "|      Joy Bennett|\n",
      "|      Paul Kriese|\n",
      "|Berniece Ornellas|\n",
      "|    Brian Farrell|\n",
      "+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SQLContext\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Exercicio Intro\").getOrCreate()\n",
    "\n",
    "\n",
    "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\", header=False, inferSchema=True)\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
    "\n",
    "df_nomes.printSchema()\n",
    "\n",
    "df_nomes.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|            Nomes|Escolaridade|\n",
      "+-----------------+------------+\n",
      "|   Frances Bennet|    Superior|\n",
      "|    Jamie Russell|       Médio|\n",
      "|   Edward Kistler| Fundamental|\n",
      "|    Sheila Maurer|       Médio|\n",
      "| Donald Golightly|    Superior|\n",
      "|       David Gray|    Superior|\n",
      "|      Joy Bennett|       Médio|\n",
      "|      Paul Kriese|       Médio|\n",
      "|Berniece Ornellas| Fundamental|\n",
      "|    Brian Farrell|       Médio|\n",
      "+-----------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, rand\n",
    "from pyspark import SparkContext, SQLContext\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Exercicio Intro\").getOrCreate()\n",
    "\n",
    "\n",
    "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\", header=False, inferSchema=True)\n",
    "\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Escolaridade',\n",
    "    when(rand() < 1/3, 'Fundamental')\n",
    "    .when(rand() < 2/3, 'Médio')\n",
    "    .otherwise('Superior'))\n",
    "\n",
    "df_nomes.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+---------------+\n",
      "|            Nomes|Escolaridade|           Pais|\n",
      "+-----------------+------------+---------------+\n",
      "|   Frances Bennet|    Superior|         Guiana|\n",
      "|    Jamie Russell|       Médio|Guiana Francesa|\n",
      "|   Edward Kistler|    Superior|       Colômbia|\n",
      "|    Sheila Maurer|    Superior|       Paraguai|\n",
      "| Donald Golightly|       Médio|Guiana Francesa|\n",
      "|       David Gray|       Médio|       Colômbia|\n",
      "|      Joy Bennett|       Médio|           Peru|\n",
      "|      Paul Kriese|       Médio|Guiana Francesa|\n",
      "|Berniece Ornellas|    Superior|         Brasil|\n",
      "|    Brian Farrell|       Médio|        Bolívia|\n",
      "+-----------------+------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, rand, lit, element_at\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Exercicio Intro\").getOrCreate()\n",
    "\n",
    "\n",
    "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\", header=False, inferSchema=True)\n",
    "\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Escolaridade',\n",
    "    when(rand() < 1/3, 'Fundamental')\n",
    "    .when(rand() < 2/3, 'Médio')\n",
    "    .otherwise('Superior'))\n",
    "\n",
    "\n",
    "paises_america_do_sul = [\"Argentina\", \"Bolívia\", \"Brasil\", \"Chile\", \"Colômbia\",\n",
    "    \"Equador\", \"Guiana\", \"Paraguai\", \"Peru\", \"Suriname\", \"Uruguai\", \"Venezuela\", \"Guiana Francesa\"]\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Pais', element_at(lit(paises_america_do_sul), ((rand() * 13 + 1).cast(\"int\"))))\n",
    "\n",
    "df_nomes.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+---------------+-------------+\n",
      "|            Nomes|Escolaridade|           Pais|AnoNascimento|\n",
      "+-----------------+------------+---------------+-------------+\n",
      "|   Frances Bennet|       Médio|Guiana Francesa|         1990|\n",
      "|    Jamie Russell|       Médio|        Uruguai|         1970|\n",
      "|   Edward Kistler|    Superior|      Argentina|         1947|\n",
      "|    Sheila Maurer|       Médio|        Equador|         1945|\n",
      "| Donald Golightly| Fundamental|        Equador|         1996|\n",
      "|       David Gray| Fundamental|      Venezuela|         1974|\n",
      "|      Joy Bennett| Fundamental|        Uruguai|         2010|\n",
      "|      Paul Kriese| Fundamental|        Bolívia|         1977|\n",
      "|Berniece Ornellas| Fundamental|         Brasil|         1965|\n",
      "|    Brian Farrell|    Superior|       Colômbia|         1984|\n",
      "+-----------------+------------+---------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, rand, lit, element_at\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Exercicio Intro\").getOrCreate()\n",
    "\n",
    "\n",
    "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\", header=False, inferSchema=True)\n",
    "\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Escolaridade',\n",
    "    when(rand() < 1/3, 'Fundamental')\n",
    "    .when(rand() < 2/3, 'Médio')\n",
    "    .otherwise('Superior'))\n",
    "\n",
    "\n",
    "paises_america_do_sul = [\"Argentina\", \"Bolívia\", \"Brasil\", \"Chile\", \"Colômbia\",\n",
    "    \"Equador\", \"Guiana\", \"Paraguai\", \"Peru\", \"Suriname\", \"Uruguai\", \"Venezuela\", \"Guiana Francesa\"]\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Pais', element_at(lit(paises_america_do_sul), ((rand() * 13 + 1).cast(\"int\"))))\n",
    "\n",
    "df_nomes = df_nomes.withColumn('AnoNascimento', lit(1945) + (rand() * (2010 - 1945 + 1)).cast(\"int\"))\n",
    "\n",
    "df_nomes.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+---------------+-------------+\n",
      "|           Nomes|Escolaridade|           Pais|AnoNascimento|\n",
      "+----------------+------------+---------------+-------------+\n",
      "|      David Gray|       Médio|          Chile|         2009|\n",
      "|     Jessie Jean|       Médio|        Bolívia|         2007|\n",
      "|     Sandra Todd|    Superior|         Guiana|         2005|\n",
      "|     Milton Rowe| Fundamental|          Chile|         2003|\n",
      "|Cristina Sheston|       Médio|Guiana Francesa|         2008|\n",
      "| Katherine Moore|       Médio|      Argentina|         2004|\n",
      "|   Sherry Wilcox|       Médio|           Peru|         2005|\n",
      "|Maurice Blizzard|       Médio|       Colômbia|         2001|\n",
      "| Suzanne Bullard| Fundamental|       Suriname|         2003|\n",
      "|    Jason Martin|       Médio|Guiana Francesa|         2000|\n",
      "+----------------+------------+---------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, rand, lit, element_at\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Exercicio Intro\").getOrCreate()\n",
    "\n",
    "\n",
    "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\", header=False, inferSchema=True)\n",
    "\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Escolaridade',\n",
    "    when(rand() < 1/3, 'Fundamental')\n",
    "    .when(rand() < 2/3, 'Médio')\n",
    "    .otherwise('Superior'))\n",
    "\n",
    "\n",
    "paises_america_do_sul = [\"Argentina\", \"Bolívia\", \"Brasil\", \"Chile\", \"Colômbia\",\n",
    "    \"Equador\", \"Guiana\", \"Paraguai\", \"Peru\", \"Suriname\", \"Uruguai\", \"Venezuela\", \"Guiana Francesa\"]\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Pais', element_at(lit(paises_america_do_sul), ((rand() * 13 + 1).cast(\"int\"))))\n",
    "\n",
    "df_nomes = df_nomes.withColumn('AnoNascimento', lit(1945) + (rand() * (2010 - 1945 + 1)).cast(\"int\"))\n",
    "\n",
    "df_select = df_nomes.select(\"*\").filter(df_nomes.AnoNascimento > 1999)\n",
    "\n",
    "df_select.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+---------+-------------+\n",
      "|         Nomes|Escolaridade|     Pais|AnoNascimento|\n",
      "+--------------+------------+---------+-------------+\n",
      "| Sheila Maurer| Fundamental| Colômbia|         2010|\n",
      "|   Joy Bennett|       Médio|    Chile|         2010|\n",
      "|  Charles Hill|       Médio|   Guiana|         2005|\n",
      "|  Rebecca Snow| Fundamental|  Uruguai|         2001|\n",
      "|Gabriel Colyer|       Médio|  Uruguai|         2008|\n",
      "| Ricky Gilbert|    Superior|    Chile|         2007|\n",
      "|   Donald Vogt| Fundamental|Venezuela|         2010|\n",
      "| Lynne Dustman|    Superior|     Peru|         2003|\n",
      "|     Ana Baker| Fundamental|  Bolívia|         2007|\n",
      "|Kenneth Winter|       Médio| Colômbia|         2001|\n",
      "+--------------+------------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, rand, lit, element_at\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Exercicio Intro\").getOrCreate()\n",
    "\n",
    "\n",
    "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\", header=False, inferSchema=True)\n",
    "\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Escolaridade',\n",
    "    when(rand() < 1/3, 'Fundamental')\n",
    "    .when(rand() < 2/3, 'Médio')\n",
    "    .otherwise('Superior'))\n",
    "\n",
    "\n",
    "paises_america_do_sul = [\"Argentina\", \"Bolívia\", \"Brasil\", \"Chile\", \"Colômbia\",\n",
    "    \"Equador\", \"Guiana\", \"Paraguai\", \"Peru\", \"Suriname\", \"Uruguai\", \"Venezuela\", \"Guiana Francesa\"]\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Pais', element_at(lit(paises_america_do_sul), ((rand() * 13 + 1).cast(\"int\"))))\n",
    "\n",
    "df_nomes = df_nomes.withColumn('AnoNascimento', lit(1945) + (rand() * (2010 - 1945 + 1)).cast(\"int\"))\n",
    "\n",
    "df_nomes.createOrReplaceTempView(\"pessoas\")\n",
    "spark.sql(\"select * from pessoas where AnoNascimento > 1999\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+---------+-------------+\n",
      "|           Nomes|Escolaridade|     Pais|AnoNascimento|\n",
      "+----------------+------------+---------+-------------+\n",
      "|Donald Golightly| Fundamental|   Guiana|         1987|\n",
      "|     Paul Kriese|    Superior|    Chile|         1992|\n",
      "|   Brian Farrell| Fundamental|Argentina|         1987|\n",
      "|   Tracy Herring| Fundamental|   Brasil|         1981|\n",
      "|    David Medina| Fundamental|Argentina|         1993|\n",
      "|     Page Marthe|       Médio|  Bolívia|         1989|\n",
      "| Helen Blackwell|       Médio|  Bolívia|         1990|\n",
      "|     Sandra Todd|    Superior|   Guiana|         1984|\n",
      "|  Rosie Lovelady| Fundamental| Suriname|         1987|\n",
      "|     Donald Vogt| Fundamental|   Brasil|         1983|\n",
      "+----------------+------------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, rand, lit, element_at\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Exercicio Intro\").getOrCreate()\n",
    "\n",
    "\n",
    "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\", header=False, inferSchema=True)\n",
    "\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Escolaridade',\n",
    "    when(rand() < 1/3, 'Fundamental')\n",
    "    .when(rand() < 2/3, 'Médio')\n",
    "    .otherwise('Superior'))\n",
    "\n",
    "\n",
    "paises_america_do_sul = [\"Argentina\", \"Bolívia\", \"Brasil\", \"Chile\", \"Colômbia\",\n",
    "    \"Equador\", \"Guiana\", \"Paraguai\", \"Peru\", \"Suriname\", \"Uruguai\", \"Venezuela\", \"Guiana Francesa\"]\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Pais', element_at(lit(paises_america_do_sul), ((rand() * 13 + 1).cast(\"int\"))))\n",
    "\n",
    "df_nomes = df_nomes.withColumn('AnoNascimento', lit(1945) + (rand() * (2010 - 1945 + 1)).cast(\"int\"))\n",
    "\n",
    "df_select = df_nomes.select(\"*\").filter(df_nomes.AnoNascimento <= 1994)\n",
    "df_select = df_select.select(\"*\").filter(df_nomes.AnoNascimento >= 1980)\n",
    "\n",
    "df_select.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+---------+-------------+\n",
      "|            Nomes|Escolaridade|     Pais|AnoNascimento|\n",
      "+-----------------+------------+---------+-------------+\n",
      "|    Jamie Russell|       Médio|Venezuela|         1980|\n",
      "|    Sheila Maurer|       Médio|    Chile|         1991|\n",
      "| Donald Golightly|       Médio|     Peru|         1988|\n",
      "|      Joy Bennett| Fundamental|  Uruguai|         1990|\n",
      "|Berniece Ornellas| Fundamental| Suriname|         1988|\n",
      "|    Brian Farrell|    Superior|   Guiana|         1990|\n",
      "|    Tracy Herring| Fundamental|    Chile|         1992|\n",
      "|  Helen Blackwell| Fundamental|   Guiana|         1992|\n",
      "|      Frank Wiley| Fundamental|   Brasil|         1986|\n",
      "|   Gabriel Colyer| Fundamental|  Bolívia|         1980|\n",
      "+-----------------+------------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, rand, lit, element_at\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Exercicio Intro\").getOrCreate()\n",
    "\n",
    "\n",
    "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\", header=False, inferSchema=True)\n",
    "\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Escolaridade',\n",
    "    when(rand() < 1/3, 'Fundamental')\n",
    "    .when(rand() < 2/3, 'Médio')\n",
    "    .otherwise('Superior'))\n",
    "\n",
    "\n",
    "paises_america_do_sul = [\"Argentina\", \"Bolívia\", \"Brasil\", \"Chile\", \"Colômbia\",\n",
    "    \"Equador\", \"Guiana\", \"Paraguai\", \"Peru\", \"Suriname\", \"Uruguai\", \"Venezuela\", \"Guiana Francesa\"]\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Pais', element_at(lit(paises_america_do_sul), ((rand() * 13 + 1).cast(\"int\"))))\n",
    "\n",
    "df_nomes = df_nomes.withColumn('AnoNascimento', lit(1945) + (rand() * (2010 - 1945 + 1)).cast(\"int\"))\n",
    "\n",
    "df_nomes.createOrReplaceTempView(\"pessoas\")\n",
    "spark.sql(\"select * from pessoas where AnoNascimento >= 1980 and AnoNascimento <= 1994\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pais</th>\n",
       "      <th>Geracao</th>\n",
       "      <th>Quantidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>174190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>175550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>186195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>233451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bolívia</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>174575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bolívia</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>174645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bolívia</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>187249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bolívia</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>233103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>175065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>175153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>186258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>232757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>174606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>174904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>186917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>232173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Colômbia</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>174597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Colômbia</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>175462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Colômbia</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>186255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Colômbia</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>233450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Equador</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>174499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Equador</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>175049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Equador</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>186078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Equador</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>233109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Guiana</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>173819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Guiana</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>174856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Guiana</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>186240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Guiana</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>233127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Guiana Francesa</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>173915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Guiana Francesa</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>175308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Guiana Francesa</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>186390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Guiana Francesa</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>231949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Paraguai</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>175147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Paraguai</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>175296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Paraguai</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>186512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Paraguai</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>233624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Peru</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>174203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Peru</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>175042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Peru</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>187267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Peru</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>232349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Suriname</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>174385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Suriname</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>174711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Suriname</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>187095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Suriname</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>233236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Uruguai</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>174251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Uruguai</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>174786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Uruguai</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>186662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Uruguai</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>233947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Geração X</td>\n",
       "      <td>174739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Millennials</td>\n",
       "      <td>174931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Geração Z</td>\n",
       "      <td>186478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Baby Boomers</td>\n",
       "      <td>234445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pais       Geracao  Quantidade\n",
       "0         Argentina     Geração X      174190\n",
       "1         Argentina   Millennials      175550\n",
       "2         Argentina     Geração Z      186195\n",
       "3         Argentina  Baby Boomers      233451\n",
       "4           Bolívia     Geração X      174575\n",
       "5           Bolívia   Millennials      174645\n",
       "6           Bolívia     Geração Z      187249\n",
       "7           Bolívia  Baby Boomers      233103\n",
       "8            Brasil     Geração X      175065\n",
       "9            Brasil   Millennials      175153\n",
       "10           Brasil     Geração Z      186258\n",
       "11           Brasil  Baby Boomers      232757\n",
       "12            Chile   Millennials      174606\n",
       "13            Chile     Geração X      174904\n",
       "14            Chile     Geração Z      186917\n",
       "15            Chile  Baby Boomers      232173\n",
       "16         Colômbia     Geração X      174597\n",
       "17         Colômbia   Millennials      175462\n",
       "18         Colômbia     Geração Z      186255\n",
       "19         Colômbia  Baby Boomers      233450\n",
       "20          Equador     Geração X      174499\n",
       "21          Equador   Millennials      175049\n",
       "22          Equador     Geração Z      186078\n",
       "23          Equador  Baby Boomers      233109\n",
       "24           Guiana     Geração X      173819\n",
       "25           Guiana   Millennials      174856\n",
       "26           Guiana     Geração Z      186240\n",
       "27           Guiana  Baby Boomers      233127\n",
       "28  Guiana Francesa     Geração X      173915\n",
       "29  Guiana Francesa   Millennials      175308\n",
       "30  Guiana Francesa     Geração Z      186390\n",
       "31  Guiana Francesa  Baby Boomers      231949\n",
       "32         Paraguai     Geração X      175147\n",
       "33         Paraguai   Millennials      175296\n",
       "34         Paraguai     Geração Z      186512\n",
       "35         Paraguai  Baby Boomers      233624\n",
       "36             Peru   Millennials      174203\n",
       "37             Peru     Geração X      175042\n",
       "38             Peru     Geração Z      187267\n",
       "39             Peru  Baby Boomers      232349\n",
       "40         Suriname   Millennials      174385\n",
       "41         Suriname     Geração X      174711\n",
       "42         Suriname     Geração Z      187095\n",
       "43         Suriname  Baby Boomers      233236\n",
       "44          Uruguai     Geração X      174251\n",
       "45          Uruguai   Millennials      174786\n",
       "46          Uruguai     Geração Z      186662\n",
       "47          Uruguai  Baby Boomers      233947\n",
       "48        Venezuela     Geração X      174739\n",
       "49        Venezuela   Millennials      174931\n",
       "50        Venezuela     Geração Z      186478\n",
       "51        Venezuela  Baby Boomers      234445"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, rand, lit, element_at\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Exercicio Intro\").getOrCreate()\n",
    "\n",
    "\n",
    "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\", header=False, inferSchema=True)\n",
    "\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Escolaridade',\n",
    "    when(rand() < 1/3, 'Fundamental')\n",
    "    .when(rand() < 2/3, 'Médio')\n",
    "    .otherwise('Superior'))\n",
    "\n",
    "\n",
    "paises_america_do_sul = [\"Argentina\", \"Bolívia\", \"Brasil\", \"Chile\", \"Colômbia\",\n",
    "    \"Equador\", \"Guiana\", \"Paraguai\", \"Peru\", \"Suriname\", \"Uruguai\", \"Venezuela\", \"Guiana Francesa\"]\n",
    "\n",
    "df_nomes = df_nomes.withColumn('Pais', element_at(lit(paises_america_do_sul), ((rand() * 13 + 1).cast(\"int\"))))\n",
    "\n",
    "df_nomes = df_nomes.withColumn('AnoNascimento', lit(1945) + (rand() * (2010 - 1945 + 1)).cast(\"int\"))\n",
    "\n",
    "df_nomes.createOrReplaceTempView(\"pessoas\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT Pais, \n",
    "       CASE \n",
    "         WHEN AnoNascimento BETWEEN 1944 AND 1964 THEN 'Baby Boomers'\n",
    "         WHEN AnoNascimento BETWEEN 1965 AND 1979 THEN 'Geração X'\n",
    "         WHEN AnoNascimento BETWEEN 1980 AND 1994 THEN 'Millennials'\n",
    "         WHEN AnoNascimento BETWEEN 1995 AND 2015 THEN 'Geração Z'\n",
    "       END AS Geracao,\n",
    "       COUNT(*) AS Quantidade\n",
    "FROM pessoas\n",
    "GROUP BY Pais, Geracao \n",
    "ORDER BY Pais, Quantidade, Geracao\n",
    "\"\"\"\n",
    "\n",
    "df_result = spark.sql(query)\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "pd_df = df_result.toPandas()\n",
    "\n",
    "\n",
    "pd_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
